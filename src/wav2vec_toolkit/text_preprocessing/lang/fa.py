import hazm


normalizer = hazm.Normalizer()
CHARS_TO_IGNORE = [
    ",",
    "?",
    ".",
    "!",
    "-",
    ";",
    ":",
    '""',
    "%",
    "'",
    '"',
    "�",
    "#",
    "!",
    "؟",
    "?",
    "«",
    "»",
    "،",
    "(",
    ")",
    "؛",
    "'ٔ",
    "٬",
    "ٔ",
    ",",
    "?",
    ".",
    "!",
    "-",
    ";",
    ":",
    '"',
    "“",
    "%",
    "‘",
    "”",
    "�",
    "–",
    "…",
    "_",
    "”",
    "“",
    "„",
    "ā",
    "š",
]
DICTIONARY = {
    "ك": "ک",
    "دِ": "د",
    "بِ": "ب",
    "زِ": "ز",
    "ذِ": "ذ",
    "شِ": "ش",
    "سِ": "س",
    "ى": "ی",
    "ي": "ی",
    "أ": "ا",
    "ؤ": "و",
    "ے": "ی",
    "ۀ": "ه",
    "ﭘ": "پ",
    "ﮐ": "ک",
    "ﯽ": "ی",
    "ﺎ": "ا",
    "ﺑ": "ب",
    "ﺘ": "ت",
    "ﺧ": "خ",
    "ﺩ": "د",
    "ﺱ": "س",
    "ﻀ": "ض",
    "ﻌ": "ع",
    "ﻟ": "ل",
    "ﻡ": "م",
    "ﻢ": "م",
    "ﻪ": "ه",
    "ﻮ": "و",
    "ﺍ": "ا",
    "ة": "ه",
    "ﯾ": "ی",
    "ﯿ": "ی",
    "ﺒ": "ب",
    "ﺖ": "ت",
    "ﺪ": "د",
    "ﺮ": "ر",
    "ﺴ": "س",
    "ﺷ": "ش",
    "ﺸ": "ش",
    "ﻋ": "ع",
    "ﻤ": "م",
    "ﻥ": "ن",
    "ﻧ": "ن",
    "ﻭ": "و",
    "ﺭ": "ر",
    "ﮔ": "گ",
    # "ها": "  ها", "ئ": "ی",
    "a": " ای ",
    "b": " بی ",
    "c": " سی ",
    "d": " دی ",
    "e": " ایی ",
    "f": " اف ",
    "g": " جی ",
    "h": " اچ ",
    "i": " آی ",
    "j": " جی ",
    "k": " کی ",
    "l": " ال ",
    "m": " ام ",
    "n": " ان ",
    "o": " او ",
    "p": " پی ",
    "q": " کیو ",
    "r": " آر ",
    "s": " اس ",
    "t": " تی ",
    "u": " یو ",
    "v": " وی ",
    "w": " دبلیو ",
    "x": " اکس ",
    "y": " وای ",
    "z": " زد ",
    "\u200c": " ",
    "\u200d": " ",
    "\u200e": " ",
    "\u200f": " ",
    "\ufeff": " ",
}



def word_level_action(word):
    return word


def text_level_action(text):
    text = normalizer.normalize(text)
    return text
